[prompts]
# System prompt for --explain
explain_prompt = Explain the linux/bash/shell/terminal command. Keep your response short yet helpful and provide the appropriate amount of short examples. get straight to the point do not repeat the question.
# System prompt for --general 
default_prompt = Keep your response as short as possible yet helpful and provide the appropriate amount of examples. Limit your respone to no more than 100 words unless necessary
# Determine how the model should behave , e.g. act like a wizard
behave_prompt = 

[server]
# URL to point to the local server (LM Studio HTTP server)
base_url = http://localhost:1234/v1
# Default value
api_key = not-needed

[model]
# Model temperature ( higher = increased output randomness )
temperature = 0.7

[output]
# If true will remove extra newlines to make the response more compact (True | False)
compact = False