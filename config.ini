[prompts]
# System prompt for --explain
explain_prompt = Explain the linux/bash/shell/terminal command. Keep your response short yet helpful and provide the appropriate amount of short examples. get straight to the point do not repeat the question.
# System prompt for --general 
default_prompt = Keep your response short yet helpful and provide the appropriate amount of examples.
# Determine how the model should behave , e.g. act like a wizard
behave_prompt = 

[server]
# URL to point to the local server (LM Studio HTTP server)
base_url = http://localhost:1234/v1
# default value
api_key = not-needed

[model]
# model temperature ( higher = increased output randomness )
temperature = 0.7
